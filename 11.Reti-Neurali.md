# Reti neurali

> Domare gli attrattori

Qui entra l'approccio discusso all'inizio del corso. Le tendenze sono mappabili con attrattori.

## Esempi d'uso

OCR: riconoscere testo da una scansione.

## Bioispiriamoci: il cervello

Un computer è molto veloce, manipola grandi quantità di dati con operazioni fisse e in modo deterministico.

Il vantaggio è che il computer è una macchina di Turing, un simulatore generale. Possiamo fare degli algoritmi.
Se troviamo un algoritmo che simula un cervello, il computer è in grado di fare quello che facciamo noi.
Una rete neurale è una simulazione delle parti essenziali.

Se un neurone è molto stimolato manda fuori il suo segnale, altrimenti no. Quindi fa una somma e poi lo fa passare per
una soglia. Il tempo tipico di elaborazione degli stimoli è 1ms.

Ogni volta che vediamo qualcosa non si accende un solo neurone. Non è che solo un gruppettino rappresenta qualcosa di
particolare, ma c'è un'attivazione distribuita nel cervello. Quindi parti diverse del cervello agiscono in sincrono
per poter elaborare oppure memorizzare i dati.

Esistono anche i neuroni specchio; ovvero neuroni che attivano aree del cervello quando interpretiamo alcune azioni.
Ad esempio per capire se qualcuno ci sta ascoltando penso a cosa farei io se stessi ascoltando qualcuno.

Siamo anche robusti a fallimenti di neuroni.

## Modello booleano

Di McCulloch e Pitts

Primo modello di neurone simulato, rete neurale.
Il modello che usano è molto semplice: ha tanti link che gli arrivano, se la somma è sotto una certa soglia $\theta$ lui
emette segnale. I livelli sono sempre 2: 0 e 1, o -1 e 1.

A ogni link in ingresso è associato un peso, che determina l'intesità del segnale in arrivo.

L'input di un neurone è la somma pesata dei weight in ingresso per il segnale emesso.

$$
I = w_1 x_1 + w_2 x_2 + \dots + w_n x_n
$$

Fanno anche degli esempi interessanti... usando questo modello posso fare delle porte logiche e se ho delle porte
logiche posso costruire qualcosa che elabori informazioni.

Un nodo che implementa l'OR ha due input, soglia 0.5 e pesi sui link di 1.
Se invece alzo la soglia a 1.5, ho realizzato un AND (l'unico modo per superare la soglia è che la somma sia 2, che
avviene solo quando entrambi sono a 1).

Se metto un peso negativo ho un NOT su un input.

Questo è il primo punto di contatto tra cervello biologico e elaborazione elettronica.

Si può realizzare anche l'XOR, ma bisogna aggiungere un livello. Mentre McCullogh e Pitts si stanno occupando solo del
percettrone semplice.

## Reti a strati

C'è uno strato di neuroni di input il cui valore è ciò che vogliamo analizzare.
Lo strato di output contiene tanti neuroni quanti i possibili stati di output del classificatore. Poi ci sono una
serie di strati intermedi.

La regola di decisione corrisponde a un iperpiano. Essenzialmente c'è qualcosa di lineare dentro. Variare i pesi
significa variare l'iperpiano.

Posso fare un AND e un OR, ma non riesco con una retta a fare un XOR. Quindi ho bisogno di due rette (l'abbiamo visto
anche come limite del modello booleano di Pitts e McCulloch).

Un percettrone semplice riesce a fare computazioni di funzioni sottostanti che sono _linearmente separabili_. L'XOR non
lo è.

## Apprendimento

Presentiamo degli esempi che sono composti così:

- variabili di input

- risposta corretta che ci aspettiamo

Adesso abbiamo bisogno di un algoritmo che cambi i pesi quando presentiamo un esempio, in modo da ottenere la risposta
desiderata. Quando la rete classifica bene da sola, l'apprendimento è completo.

$$
y = H(\sum w_k x_k - T)
$$

la funzione $H$ è la funzione di excite, se sono sotto 0 (cioè sotto soglia) ritorna 0, altrimenti 1.
Per calcolare più velocemente il $-T$ è sufficiente aggiungere un input fittizio in più, con valore $x_0=1$ e peso
$w_0 = -T$. Questo semplifica la notazione. $y = H(w x')$ se w e x sono righe.

La risposta desiderata $y_d$ determina la regola di aggiornamento. Sia $y$ la risposta della rete, allora aggiorniamo
i pesi come segue:

$$
\begin{cases}
y = y_d \Rightarrow W(k+1) = W(k)
y \lt y_d \Rightarrow W(k+1) = W(k) + \epsilon x
y \gt y_d \Rightarrow W(k+1) = W(k) - \epsilon x
\end{cases}
$$

### Teorema del percettrone

> Se la funzione è booleana, e a soglia, e il problema è linearmente separabile, allora la funzione riesce a risolvere
i pesi in un numero finito di passi.

Dare il valore di $\epsilon$ è un po' un'arte. È chiamato **tasso di apprendimento** e misura l'impatto di ogni singolo
esempio sul training.

L'apprendimento comporta un premio o una punizione per ogni esempio.

La performance delle rete si calcola in grado a quanto può generalizzare, se presentandole degli esempi mai visti dà
delle risposte corrette allora si comporta bene.

Esiste un altro algoritmo per reti con più strati, il _gradient backpropagation_.

## Funzioni di trasferimento

Alternativa al trigger booleano.

Squashing functions come

$$
f(x) = \frac{A}{1 + be^{-kx}}
$$

Tutte le funzioni di trasferimento sono monotone non decrescenti.

Quando l'errore che hai fatto è minimo vuol dire che stai dando delle buone risposte.

## Funzione di errore

$$
E_i = (y - y_i^d)^2
$$

è la norma 2 della differenza vettoriale. L'apprendimento diventa una minimizzazione, perché lo scopo della rete è
mandare questa funzione al minimo. L'apprendimento è un minimizzatore.

Per andare verso i minimi seguiamo il gradiente. Per far variare w consideriamo la derivata della funzione di errore.
Stiamo quindi seguendo il gradiente.

Il problema degli esempi è che può non esistere un'unica regola per spiegarli.

Overfitting: ho imparato a memoria. Non va bene.