# Agenti

Sistemi multiagente: emergono sovrastrutture, ad esempio il web dove sono emerse isole e zone dove si diffonde
la conoscenza che non erano nella mente di chi l'ha pensato.

Emergenza: come utilizzarla per far emergere le sovrastrutture in modo controllato.

## Definizione

Partiamo definendo l'agenzia: è un processo che ha dei fini, ad esempio un'agenzia di commercio.
È anche lo stato di fare servizio come delegato ufficiale, tipo un agente commercio.

Lo stato di essere in azione o esercitare potere.

Boiled down: le agenzie **possono fare**.

Gli agenti hanno degli scopi ben precisi (ad esempio le spie), sono delegati da qualcun altro (un governo, un proprietario
di un immobile etc.) e **sanno come fare** (hanno il permesso e il potere di agire).

Noi diamo solo degli obiettivi agli agenti, loro autonomamente stabiliscono la strategia per risolvere.

In altri ambiti gli agenti sono:

- un tipo di virus (biologia)

- un nome che effettua un'azione (linguistica)

- una persona che decide su questioni che coinvolgono gli interessi del titoale (microeconomia)

- agenti software: user agent, management agent (informatica)

Quando progettiamo un software con architettura client-server stiamo ragionando con degli agenti.

### Definizione corporea

Un agente è un'unità computazionale, fa elaborazione, che può essere in grado di percepire e agire
nel suo ambiente e ha un comportamento autonomo che almeno parzialmente dipende dalla sua esperienza personale.

Questa definizione è corporea perché è fatta su di noi. Gambe e braccia per agire sull'ambiente, degli stati
interni perché elaboriamo e reagiamo a quello che ci succede.

L'agente è un'unità computazionale; devo tenere in considerazione tutte le parti.
Tutto ciò che non è agente è **ambiente**, e l'agente vive e percepisce nell'ambiente. Importantissimo!
Mentre progetto all'agente, anche se non ho pensato allo scambio di informazioni con l'ambiente, questo
non vuol dire che non avverrà.

Il potere che dò all'agente sono gli scopi e le regole in cui agire. Praticamente il potere di ingaggio.

### Definizione sociale

Gli agenti sono le persone delle società artificiali. Ogni agente ha degli stati interni e delle regole comportamentali
che possono cambiare con l'interazione con altri agenti, oppure rimanere fissi.

Gli stati posso essere costanti o variabili. Nozione più adatti per i sistemi multiagente.

Spesso gli agenti costituiscono l'ambiente degli altri agenti. Lo scambio di informazione è anche non esplicito.

Un agente è in grado di percepire **parzialmente** il suo ambiente. Posso fare diverse ipotesi ma non ho la
percezione completa del mio ambiente.

Spesso gli agenti non calcolano ma reagiscono agli stimoli: tipo reattivo. Ad esempio se vedo uno che mi tira
un sasso mi sposto, se i miei calcoli mi dicono che il sasso cadrà molto prima non mi sposto.

Possono essere in grado di riprodursi, non in modo perfetto per cui ci sono delle piccole mutazioni "genetiche".

## Paradigmi

Paradigma debole: un agente è autonomo, reattivo, pro-attivo (comportamento diretto ad obiettivi),
socialmente abile (capace di comunicare con gli altri agenti, con gli umani).

Gli agenti proattivi non sono tanti, quelli che provocano nell'ambiente il cambiamento che vogliono vedere.
Non aspettano di reagire un cambiamento ma "prevedono" quello che accadrà. Sono molto intelligenti.
Sa che le cose cambieranno e fa in modo che non accadano. 

L'abilità sociale può provocare la coalizione di agenti o gruppi. Formiamo un gruppo quando serve e disfarlo
quando non è più necessario.

Paradigma forte: aggiungiamo altre proprietà alle precedenti: conoscenza, intenzioni, emozioni, senso d'obbligo,
scopi...

Perché fare agenti software con emozioni? Spesso scelgono male se non hanno emozioni. In che modo stiamo interpretando
la parola emozione? Oltre al raziocinio e all'intelligenza, l'essere umano ha tanti tipi di intelligenza ma ha
anche le emozioni.

Le emozioni concorrono a prendere decisioni, quando non ho abbastanza dati che mi permettono di scegliere.
Ci sono casi noti in cui danneggiando la parte emozionale del cervello, chi deve scegliere fa tutti i conti
e non arriva al bilancio di scelta.

[Sony AIBO](https://www.youtube.com/watch?v=uLEhlbjrkVA)

Nel paradigma forte ci sono caratteristiche che non esistono nel paradigma debole. È quello che noi vorremmo
che fosse un robot.

Autoconservazione -> il robot deve conservarsi, ma nelle leggi di Asimov ha dei limiti. Occorre una gerarchia
di obiettivi o di valori che devono essere soddisfatti.
Questo è un metascopo, che permette di raggiungere i suoi scopi.

Questo tipo di robotica richiede anche filosofia, etica e discipline che escono dall'informatica in senso stretto.

## Agentizzazione

Finora abbiamo agentizzato molte cose:

- il sistema non trova il file

- il database vuole un formato differente

- il programma non accetta questo tipo di dato (ci immaginiamo un programma irritato)

noi viviamo in un mondo di agenti e queste frasi sono molto efficaci. Però il database non vuole fisicamente qualcosa.
Posizionale intenzionale.

Noi siamo convinti che il nostro agente sia autonomo, che è la nozione più ambigua incontrata finora.
Spesso l'autonomia è limitata. Non c'è nulla di veramente autonomo, però ci saranno dei programmi che ci sorprendono e che
sappiamo dove vanno a finire.

Spesso si studiano gli agenti finali per sapere come fanno a fare quello che fanno, perché è il processo che ha
plasmato gli agenti. Faremo quindi degli _esperimenti_.

Altre caratteristiche:

- mobilità;

- veridicità (truth): correttezza nella produzione di informazioni. È un modo per fare load balance;

- benevolezza: correttezza delle informazioni;

- razionalità

sono aggettivi che uno darebbe a degli esseri umani. Ho definito in che modo sono concretizzati.

Fin qui abbiamo idee generali.

## Architetture di agente

Devo disegnare un agente, che architetture posso usare per disegnare un agente?

- logic-based, la prima venuta in mente, è quella che dà autonomia ed è deduzione logica e matematica.
    Nel 57 hanno presentato un agente capace di dimostrare teoremi matematici. Non si è accorto di aver provato
    qualcosa di interessante e andava avanti, altrimenti saremmo già in AI molto forte.

    [Logic Theory Machine](https://en.wikipedia.org/wiki/Logic_Theorist)

- reactive: la decisione è relaizzata come mappature tra azione e situazione.

- belief-desire-intention (BDI):
    ho delle credenze sull'ambiente (percezioni), ciò che penso che l'ambiente sia

    il desire è il mio obiettivo (motivazione interna)

    le intenzioni invece sono gli stati deliberativi dell'agente

    questo è il robot dannatamente computazionale. Robot lavapavimenti che si inceppa, la computazione
    non avviene abbastanza velocemente o cambia l'ambiente troppo velocemente.

- layered: la parte di decisione è realizzata con diversi livelli, ciascuno dei quali è più o meno
    esplicitamente dotato di capacità cognitive riguardo all'ambiente. La parte raziocinante è usata
    solo quando c'è tempo di farla.

### Comportamenti

Classificazione in base al punto di vista del robot: interno o esterno.

Teleonomico se è diretto verso un comportamento esplicito. Riflessivo quando è regolato sulle proprie
percezioni interne.

### Aspetti cognitivi

Sempre visto dall'esterno.

Cognitivo se ha una rappresentazione esplicita del mondo, altrimenti è reattivo embodied che rappresenta
in modo sub-simbolico il mondo integrato nelle sue capacità motorie.

Hanno una rappresentazione talmente elaborata che fanno piccole simulazioni. Possono memorizzare situazioni
da analizzare e pianificare il proprio comportamento. Prevedono le conseguenze delle proprie azioni.
Costruiscono piani e ottimizzano il numero di movimenti.

Qui rientra anche la swarm intelligence.

Le reti neurali hanno una rappresentazione sub-simbolica. Ogni oggetto è tale per cui ha degli attributi e dei
metodi (il proiettore si può accendere etc.). La rete neurale non ha alcuna variabile interna che rappresenta
gli oggetti con cui interagisce. Intelligenza sparsa nel corpo e non simbolica.
Lo approfondiamo nelle reti neurali.
